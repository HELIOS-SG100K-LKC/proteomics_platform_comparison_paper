{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression_fdr(df_pheno, df_proteome, Protein_ID, platform_name, df_proteome_median, type):\n",
    "    def run_regression(y, X, family):\n",
    "        X = sm.add_constant(X)  # Add constant term for intercept\n",
    "        if family == 'binomial':\n",
    "            model = sm.GLM(y, X, family=sm.families.Binomial()).fit()\n",
    "        else:\n",
    "            model = sm.GLM(y, X, family=sm.families.Gaussian()).fit()\n",
    "        return model\n",
    "\n",
    "    df_proteome = df_proteome.to_numpy()\n",
    "\n",
    "    # Define the dependent variables and their respective covariates\n",
    "    regression_config = {\n",
    "        'Age': (['Sex', 'Bmi'], 'gaussian'),\n",
    "        'Sex': (['Age', 'Bmi'], 'binomial'),\n",
    "        'Bmi': (['Age', 'Sex'], 'gaussian')\n",
    "    }\n",
    "    # Define common covariates\n",
    "    common_covariates = ['FREG5_Ethnic_Group_I', 'FREG5_Ethnic_Group_M']\n",
    "    results = {dep_var: [] for dep_var in regression_config}\n",
    "\n",
    "    for i in range(df_proteome.shape[1]):\n",
    "        protein_data = df_proteome[:, i]\n",
    "        \n",
    "        for dep_var, (covariates, family) in regression_config.items():\n",
    "            X = np.column_stack((protein_data, df_pheno[covariates].values, df_pheno[common_covariates].values))\n",
    "            model = run_regression(df_pheno[dep_var], X, family)\n",
    "            results[dep_var].append([\n",
    "                Protein_ID[i], model.params.iloc[1], model.bse.iloc[1], model.tvalues.iloc[1], model.pvalues.iloc[1]\n",
    "            ])\n",
    "\n",
    "    significance_value = 0.05\n",
    "    bonferroni_threshold = significance_value / len(Protein_ID)\n",
    "    significant_results = {}\n",
    "    top_10_results = {}\n",
    "    allresults = {}\n",
    "\n",
    "    print(f\"Number of samples: {df_pheno.shape[0]}\")\n",
    "    print(f\"Number of proteins: {df_proteome.shape[1]}\")\n",
    "\n",
    "    for dep_var, result_list in results.items():\n",
    "        columns = ['Protein_ID', 'Est', 'SE', 't_value', 'P']\n",
    "        res_df = pd.DataFrame(result_list, columns=columns)\n",
    "\n",
    "        # Print uncorrected p-value threshold\n",
    "        print(f\"Uncorrected p-value threshold: {significance_value}\")\n",
    "        print(f\"Bonferroni correction threshold: {bonferroni_threshold}\")\n",
    "\n",
    "        res_df = res_df.dropna(subset=['P'])\n",
    "\n",
    "        # FDR correction\n",
    "        res_df['FDR_P'] = multipletests(res_df['P'], method='fdr_bh')[1]\n",
    "\n",
    "        # Bonferroni correction\n",
    "        res_df['Bonferroni_P'] = res_df['P'] < bonferroni_threshold\n",
    "\n",
    "        # Find and print the FDR p-value threshold\n",
    "        try:\n",
    "            fdr_threshold = res_df[res_df['FDR_P'] < significance_value]['FDR_P'].max()\n",
    "            print(f\"FDR-corrected p-value threshold for {dep_var}: {fdr_threshold}\")\n",
    "        except:\n",
    "            print(f\"No significant results found for {dep_var} after FDR correction\")\n",
    "\n",
    "        print(f\"Number of significant results for {dep_var} (uncorrected): {res_df[res_df['P'] < significance_value].shape[0]}\")\n",
    "        print(f\"Number of significant results for {dep_var} (FDR corrected): {res_df[res_df['FDR_P'] < significance_value].shape[0]}\")\n",
    "        print(f\"Number of significant results for {dep_var} (Bonferroni corrected): {res_df[res_df['Bonferroni_P']].shape[0]}\")\n",
    "\n",
    "        # Filter significant results using FDR-corrected p-values\n",
    "        sig_res_df = res_df[res_df['FDR_P'] < significance_value]\n",
    "        significant_results[dep_var] = sig_res_df\n",
    "\n",
    "        # Annotate with Uniprot ID names\n",
    "        uniprot = pd.read_csv(\"../data/uniprotkb_Human_AND_model_organism_9606_2024_05_20.tsv\", sep='\\t')\n",
    "        uniprot = uniprot.iloc[:, [0, 3, 4, 7]]\n",
    "\n",
    "        final_out = pd.merge(res_df, uniprot, left_on='Protein_ID', right_on='Entry', how='left')\n",
    "        final_out = final_out.sort_values(by='FDR_P')\n",
    "        final_out = pd.merge(final_out, df_proteome_median, left_on='Protein_ID', right_index=True, how='left')\n",
    "\n",
    "        allresults[dep_var] = final_out\n",
    "        # Save annotated results file\n",
    "        output_file = f\"./output/all/{platform_name}_{dep_var.lower()}_associations_{type}_fdr_corrected.csv\"\n",
    "        final_out.to_csv(output_file, sep='\\t', index=False)\n",
    "        print(f\"Saved all {dep_var} associations to {output_file}\")\n",
    "\n",
    "        #save significant results\n",
    "        sig_output_file = f\"./output/significant/{platform_name}_{dep_var.lower()}_significant_associations_{type}_fdr_corrected.csv\"\n",
    "        sig_res_df.to_csv(sig_output_file, sep='\\t', index=False)\n",
    "        print(f\"Saved significant {dep_var} associations to {sig_output_file}\")\n",
    "\n",
    "        # Store the top 10 significant results for each dependent variable\n",
    "        top_10_results[dep_var] = final_out.head(10)\n",
    "\n",
    "    # Lookup known associations by Uniprot ID (example: P15502)\n",
    "    lookup_results = {dep_var: final_out[final_out['Protein_ID'] == \"P15502\"] for dep_var, final_out in allresults.items()}\n",
    "\n",
    "    return significant_results, top_10_results, lookup_results, allresults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_olink_data(tech_rep, normalization):\n",
    "    \"\"\"\n",
    "    Process Olink data.\n",
    "    \n",
    "    Parameters:\n",
    "        tech_rep: int or str\n",
    "            Technical replicate identifier to filter unique participants.\n",
    "        normalization: bool\n",
    "            Whether to apply inverse normal transformation to phenotypes.\n",
    "            \n",
    "    Returns:\n",
    "        tuple: (df_pheno, df_proteome, df_proteome_median, df_unique)\n",
    "    \"\"\"\n",
    "    # Read Olink data\n",
    "    merged_df = pd.read_csv(\"../../data/olink/Preprocessed_data_intensity_normalized/Olink_Merged_All.csv\")\n",
    "    \n",
    "    # Load phenotype data\n",
    "    pheno = pd.read_csv(\"../data/HELIOS_Core_v4.csv\")\n",
    "    \n",
    "    # Filter unique participants based on tech_rep\n",
    "    df_unique = merged_df[(merged_df['tech_rep_id'] == \"N\") & (merged_df['bio_rep_id'] == \"N\") | (merged_df['tech_rep'] == tech_rep)]\n",
    "    \n",
    "    # Subset and factorize phenotypes\n",
    "    pheno = (pheno\n",
    "             .assign(Bmi=lambda x: 100*100*x['DBI14_Weight'] / (x['DBI13_Height']**2))\n",
    "             .assign(Age=lambda x: x['FREG8_Age'],\n",
    "                     Sex=lambda x: np.where(x['FREG7_Gender'] == \"F\", 1, 0))\n",
    "             .loc[:, ['FREG1_Barcode', 'Age', 'Sex', 'FREG5_Ethnic_Group', 'Bmi']]\n",
    "             .query('FREG5_Ethnic_Group != \"O\"'))\n",
    "\n",
    "    pheno['Sex'] = pheno['Sex'].astype('category')\n",
    "    \n",
    "    # Convert 'FREG5_Ethnic_Group' to categorical dummy variables (drop_first=True like in original)\n",
    "    pheno = pd.get_dummies(pheno, columns=['FREG5_Ethnic_Group'], drop_first=True)\n",
    "    \n",
    "    # Merge phenotype and proteomics data\n",
    "    df_unique = pd.merge(pheno, df_unique, on='FREG1_Barcode')\n",
    "    \n",
    "    # Separate phenotype and proteomic datasets\n",
    "    # Use the same column indexing as your original working code\n",
    "    df_pheno = df_unique.iloc[:, :24]  # First 24 columns for phenotype\n",
    "    df_proteome = df_unique.iloc[:, 24:]  # Remaining columns for proteome\n",
    "    \n",
    "    # Remove proteins with only one unique value (like in your original code)\n",
    "    df_proteome = df_proteome.loc[:, df_proteome.apply(lambda x: x.nunique()) != 1]\n",
    "    \n",
    "    def inverse_normal_transform(series):\n",
    "        ranks = stats.rankdata(series)  # Rank the data\n",
    "        ranks = (ranks - 0.5) / len(series)  # Convert ranks to percentiles\n",
    "        transformed = stats.norm.ppf(ranks)  # Apply inverse normal transformation\n",
    "        return transformed\n",
    "\n",
    "    # Do rank-based inverse normal transformation of the phenotypes Age and BMI to make them normally distributed\n",
    "    if normalization == True:\n",
    "        df_pheno['Age'] = inverse_normal_transform(df_pheno['Age'])\n",
    "        df_pheno['Bmi'] = inverse_normal_transform(df_pheno['Bmi'])\n",
    "    \n",
    "    # Calculate median for proteomic data (same as your original code)\n",
    "    df_proteome_median = df_proteome.median()\n",
    "    df_proteome_median = df_proteome_median.reset_index()\n",
    "    df_proteome_median.columns = ['Protein', 'Median']\n",
    "    df_proteome_median.set_index('Protein', inplace=True)\n",
    "    \n",
    "    return df_pheno, df_proteome, df_proteome_median, df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process Olink data\n",
    "df_pheno, df_proteome, df_proteome_median, df_unique = process_olink_data(1, True)\n",
    "proteins= df_proteome.columns\n",
    "display(df_pheno.head())\n",
    "display(df_proteome.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common proteins (UniProt IDs): 1740\n",
      "Number of corresponding Olink IDs: 1742\n",
      "Average Olink IDs per UniProt ID: 1.00\n",
      "Max Olink IDs for a single UniProt ID: 3\n"
     ]
    }
   ],
   "source": [
    "#generate the column names from the common proteins file\n",
    "common_proteins = pd.read_csv(\"common_proteins_soma_olink_thermo.txt\", header=None)\n",
    "common_proteins.columns = ['Proteins']\n",
    "common_proteins_list = common_proteins['Proteins'].tolist()\n",
    "\n",
    "#convert the common_proteins_list which are uniprot IDs to ALL matching olink IDs\n",
    "def convert_uniprot_to_olink(uniprot_list):\n",
    "    olink_to_uniprot = pd.read_csv(\"Olink_Assay_Annotation_All.csv\")\n",
    "    olink_to_uniprot = olink_to_uniprot.loc[:, ['OlinkID', 'UniProt']]\n",
    "    \n",
    "    # Filter rows where UniProt is in the common_proteins_list\n",
    "    matching_proteins = olink_to_uniprot[olink_to_uniprot['UniProt'].isin(uniprot_list)]\n",
    "    \n",
    "    # Return all OlinkIDs that match\n",
    "    return matching_proteins['OlinkID'].tolist()\n",
    "\n",
    "common_proteins_olink = convert_uniprot_to_olink(common_proteins_list)\n",
    "\n",
    "print(f\"Number of common proteins (UniProt IDs): {len(common_proteins_list)}\")\n",
    "print(f\"Number of corresponding Olink IDs: {len(common_proteins_olink)}\")\n",
    "\n",
    "# Optional: Check the mapping ratio\n",
    "olink_annotation = pd.read_csv(\"Olink_Assay_Annotation_All.csv\")\n",
    "mapping_counts = olink_annotation[olink_annotation['UniProt'].isin(common_proteins_list)].groupby('UniProt').size()\n",
    "print(f\"Average Olink IDs per UniProt ID: {mapping_counts.mean():.2f}\")\n",
    "print(f\"Max Olink IDs for a single UniProt ID: {mapping_counts.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common(df_unique, use_common_samples=True, use_common_proteins=True):\n",
    "    if use_common_samples:\n",
    "        # Read common samples\n",
    "        common_samples = pd.read_csv(\"common_samples.csv\", header=None)\n",
    "        common_samples.columns = ['FREG0_PID']\n",
    "\n",
    "        # Filter the samples from df_unique\n",
    "        df_unique_filter = df_unique[df_unique['FREG0_PID'].isin(common_samples['FREG0_PID'])]\n",
    "    else:\n",
    "        df_unique_filter = df_unique\n",
    "\n",
    "    if use_common_proteins:\n",
    "        # Filter the proteins from df_unique_filter using common_proteins\n",
    "        df_unique_proteome = df_unique_filter.iloc[:, 23:]\n",
    "        df_unique_proteome = df_unique_proteome[common_proteins_olink]\n",
    "    else:\n",
    "        df_unique_proteome = df_unique_filter.iloc[:, 23:]\n",
    "\n",
    "    # Separate into phenotype and proteomic datasets\n",
    "    df_pheno_filter = df_unique_filter.iloc[:, :23]\n",
    "    df_proteome_filter = df_unique_proteome\n",
    "\n",
    "    # Remove proteins with only one value\n",
    "    df_proteome_filter = df_proteome_filter.loc[:, df_proteome_filter.apply(lambda x: x.nunique()) != 1]\n",
    "\n",
    "    return df_pheno_filter, df_proteome_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_protein_list():\n",
    "    #read xlsx file\n",
    "    df1 = pd.read_excel('../../platform_analytes_list/explore-1536-assay-list-20210227-web-1.xlsx', header=1)\n",
    "    uniprot_list_v1 = df1['Uniprot ID'].tolist()\n",
    "   \n",
    "    \n",
    "    df2 = pd.read_excel('../../platform_analytes_list/olink-explore-3072-validation-data-results.xlsx', header=1)\n",
    "    uniprot_list_v2 = df2['UniProt'].tolist()\n",
    "    #display(df2.head())\n",
    "\n",
    "    df3 = pd.read_csv('../../data/olink/Preprocessed_data_intensity_normalized/Olink_Assay_Annotation_All.csv',header=0)\n",
    "    #display(df3.head())\n",
    "    data3 = df3.loc[:, ['OlinkID', 'UniProt']]\n",
    "    #display(data3.head())\n",
    "    uniprot_list_v3 = df3['UniProt'].tolist()\n",
    "    olinkid_v3 = df3['OlinkID'].tolist()\n",
    "\n",
    "\n",
    "    uniprot_to_olinkid = dict(zip(data3['UniProt'], data3['OlinkID']))\n",
    "\n",
    "    df_lod = pd.read_csv(\"../../data/olink/Preprocessed_data_intensity_normalized/Olink_HighProportionProteins_0.2_Intensity.csv\")\n",
    "    uniprot_lod = df_lod['UniProt'].to_list()\n",
    "    olinkid_lod = df_lod['OlinkID'].to_list()\n",
    "\n",
    "    #function to convert uniprot to olinkid\n",
    "    def convert_uniprot_to_olinkid(uniprot_list, uniprot_to_olinkid):\n",
    "        return list(filter(None, map(lambda uniprot: uniprot_to_olinkid.get(uniprot), uniprot_list)))\n",
    "    \n",
    "    olinkid_v1 = convert_uniprot_to_olinkid(uniprot_list_v1, uniprot_to_olinkid)\n",
    "    olinkid_v2 = convert_uniprot_to_olinkid(uniprot_list_v2, uniprot_to_olinkid)\n",
    "    uniprot_list_set1 = uniprot_list_v1\n",
    "    uniprot_list_set2 = list(set(uniprot_list_v2) - set(uniprot_list_v1))\n",
    "    uniprot_list_set3 = list(set(uniprot_list_v3) - set(uniprot_list_v2))\n",
    "    olinkid_set1 = olinkid_v1\n",
    "    olinkid_set2 = list(set(olinkid_v2) - set(olinkid_v1))\n",
    "    olinkid_set3 = list(set(olinkid_v3) - set(olinkid_v2))\n",
    "\n",
    "\n",
    "    return uniprot_list_set1, uniprot_list_set2, uniprot_list_set3, uniprot_lod, olinkid_set1, olinkid_set2, olinkid_set3, olinkid_lod\n",
    "\n",
    "def return_set_breakdown (proteinlist, sequencelist):\n",
    "    set1, set2, set3, lod, olinkid_set1, olinkid_set2, olinkid_set3, olinkid_lod = return_protein_list()\n",
    "    set1_count = len(set(proteinlist) & set(set1))\n",
    "    set2_count = len(set(proteinlist) & set(set2))\n",
    "    set3_count = len(set(proteinlist) & set(set3))\n",
    "    lod_count = len(set(proteinlist) & set(lod))\n",
    "\n",
    "    olinkid_set1_count = len(set(sequencelist) & set(olinkid_set1))\n",
    "    olinkid_set2_count = len(set(sequencelist) & set(olinkid_set2))\n",
    "    olinkid_set3_count = len(set(sequencelist) & set(olinkid_set3))\n",
    "    olinkkid_lod_count = len(set(sequencelist) & set(olinkid_lod))\n",
    "    return set1_count, set2_count, set3_count, lod_count, olinkid_set1_count, olinkid_set2_count, olinkid_set3_count, olinkkid_lod_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def olinkid_to_uniprot(olinklist):\n",
    "    df = pd.read_csv(\"Olink_Assay_Annotation_All.csv\")\n",
    "    df = df.loc[:, ['OlinkID', 'UniProt']]\n",
    "    #create a dictionary\n",
    "    olink_to_uniprot = dict(zip(df['OlinkID'], df['UniProt']))\n",
    "    return list(set(list(filter(None, map(lambda olink: olink_to_uniprot.get(olink), olinklist)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 46\n",
      "Number of proteins: 1742\n",
      "Uncorrected p-value threshold: 0.05\n",
      "Bonferroni correction threshold: 2.870264064293915e-05\n",
      "FDR-corrected p-value threshold for Age: 0.049367507167352685\n",
      "Number of significant results for Age (uncorrected): 212\n",
      "Number of significant results for Age (FDR corrected): 71\n",
      "Number of significant results for Age (Bonferroni corrected): 21\n",
      "Saved all Age associations to ./output/all/olink_age_associations_common_protein_common_sample_fdr_corrected.csv\n",
      "Saved significant Age associations to ./output/significant/olink_age_significant_associations_common_protein_common_sample_fdr_corrected.csv\n",
      "Uncorrected p-value threshold: 0.05\n",
      "Bonferroni correction threshold: 2.870264064293915e-05\n",
      "FDR-corrected p-value threshold for Sex: nan\n",
      "Number of significant results for Sex (uncorrected): 168\n",
      "Number of significant results for Sex (FDR corrected): 0\n",
      "Number of significant results for Sex (Bonferroni corrected): 0\n",
      "Saved all Sex associations to ./output/all/olink_sex_associations_common_protein_common_sample_fdr_corrected.csv\n",
      "Saved significant Sex associations to ./output/significant/olink_sex_significant_associations_common_protein_common_sample_fdr_corrected.csv\n",
      "Uncorrected p-value threshold: 0.05\n",
      "Bonferroni correction threshold: 2.870264064293915e-05\n",
      "FDR-corrected p-value threshold for Bmi: 0.04962083169034301\n",
      "Number of significant results for Bmi (uncorrected): 318\n",
      "Number of significant results for Bmi (FDR corrected): 60\n",
      "Number of significant results for Bmi (Bonferroni corrected): 19\n",
      "Saved all Bmi associations to ./output/all/olink_bmi_associations_common_protein_common_sample_fdr_corrected.csv\n",
      "Saved significant Bmi associations to ./output/significant/olink_bmi_significant_associations_common_protein_common_sample_fdr_corrected.csv\n",
      "\n",
      "Age (Olink):\n",
      "Number of total OlinkIDs:  1742 Number of total proteins:  1740\n",
      "Number of lod OlinkIDs:  543 Number of lod proteins:  542\n",
      "Number of significant OlinkIDs: 71 Number of significant proteins:  71\n",
      "Protein Breakdown\n",
      "Age: Set 1: 45/790, Set 2: 22/596, Set 3: 4/354\n",
      "Age: Below LoD: 4/542, Above LoD: 67/1198\n",
      "OlinkID Breakdown\n",
      "Age: Set 1: 45/790, Set 2: 22/596, Set 3: 4/356\n",
      "Age: Below LoD: 4/543, Above LoD: 67/1199\n",
      "\n",
      "Sex (Olink):\n",
      "Number of total OlinkIDs:  1742 Number of total proteins:  1740\n",
      "Number of lod OlinkIDs:  543 Number of lod proteins:  542\n",
      "Number of significant OlinkIDs: 0 Number of significant proteins:  0\n",
      "Protein Breakdown\n",
      "Sex: Set 1: 0/790, Set 2: 0/596, Set 3: 0/354\n",
      "Sex: Below LoD: 0/542, Above LoD: 0/1198\n",
      "OlinkID Breakdown\n",
      "Sex: Set 1: 0/790, Set 2: 0/596, Set 3: 0/356\n",
      "Sex: Below LoD: 0/543, Above LoD: 0/1199\n",
      "\n",
      "Bmi (Olink):\n",
      "Number of total OlinkIDs:  1742 Number of total proteins:  1740\n",
      "Number of lod OlinkIDs:  543 Number of lod proteins:  542\n",
      "Number of significant OlinkIDs: 60 Number of significant proteins:  60\n",
      "Protein Breakdown\n",
      "Bmi: Set 1: 45/790, Set 2: 13/596, Set 3: 2/354\n",
      "Bmi: Below LoD: 3/542, Above LoD: 57/1198\n",
      "OlinkID Breakdown\n",
      "Bmi: Set 1: 45/790, Set 2: 13/596, Set 3: 2/356\n",
      "Bmi: Below LoD: 3/543, Above LoD: 57/1199\n"
     ]
    }
   ],
   "source": [
    "df_pheno_common, df_proteome_common = common(df_unique, use_common_samples=True, use_common_proteins=True)\n",
    "Protein_ID_common = df_proteome_common.columns\n",
    "Protein_ID_common_uniprot = olinkid_to_uniprot(Protein_ID_common)\n",
    "\n",
    "# Perform regression analysis on common samples and proteins for Olink data\n",
    "significant_results_common, top_10_common, lookup_result_common, results_common = perform_regression_fdr(\n",
    "    df_pheno_common, \n",
    "    df_proteome_common, \n",
    "    Protein_ID_common, \n",
    "    \"olink\", \n",
    "    df_proteome_median, \n",
    "    type=\"common_protein_common_sample\"\n",
    ")\n",
    "\n",
    "# Display results breakdown for Olink common data\n",
    "for key in significant_results_common.keys():\n",
    "    set1_count_total, set2_count_total, set3_count_total, lod_count_total, olinkid_set1_count_total, olinkid_set2_count_total, olinkid_set3_count_total, olinkid_lod_count_total = return_set_breakdown(Protein_ID_common_uniprot, Protein_ID_common)\n",
    "    significant_olinkids = significant_results_common[key]['Protein_ID'].to_list()\n",
    "    associated_proteins = olinkid_to_uniprot(significant_olinkids)\n",
    "    \n",
    "    print(f\"\\n{key} (Olink):\")\n",
    "    print(\"Number of total OlinkIDs: \", len(Protein_ID_common), \"Number of total proteins: \", len(Protein_ID_common_uniprot))\n",
    "    print(\"Number of lod OlinkIDs: \", olinkid_lod_count_total, \"Number of lod proteins: \", lod_count_total)\n",
    "    print(f\"Number of significant OlinkIDs: {len(significant_olinkids)}\", \"Number of significant proteins: \", len(associated_proteins))\n",
    "    set1_count_associated, set2_count_associated, set3_count_associated, lod_count_associated, olinkid_set1_count_associated, olinkid_set2_count_associated, olinkid_set3_count_associated, olinkid_lod_count_associated = return_set_breakdown(associated_proteins, significant_olinkids)\n",
    "    \n",
    "    print(\"Protein Breakdown\")\n",
    "    print(f\"{key}: Set 1: {set1_count_associated}/{set1_count_total}, Set 2: {set2_count_associated}/{set2_count_total}, Set 3: {set3_count_associated}/{set3_count_total}\")\n",
    "    print(f\"{key}: Below LoD: {lod_count_associated}/{lod_count_total}, Above LoD: {len(associated_proteins) - lod_count_associated}/{len(Protein_ID_common_uniprot) - lod_count_total}\")\n",
    "    \n",
    "    print(\"OlinkID Breakdown\")\n",
    "    print(f\"{key}: Set 1: {olinkid_set1_count_associated}/{olinkid_set1_count_total}, Set 2: {olinkid_set2_count_associated}/{olinkid_set2_count_total}, Set 3: {olinkid_set3_count_associated}/{olinkid_set3_count_total}\")\n",
    "    print(f\"{key}: Below LoD: {olinkid_lod_count_associated}/{olinkid_lod_count_total}, Above LoD: {len(significant_olinkids) - olinkid_lod_count_associated}/{len(Protein_ID_common) - olinkid_lod_count_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to return the number of unique uniprot IDs given a list of olink IDs\n",
    "def count_unique_uniprot_ids_olink(olink_ids):\n",
    "    olink_to_uniprot = pd.read_csv(\"Olink_Assay_Annotation_All.csv\")\n",
    "    olink_to_uniprot = olink_to_uniprot.loc[:, ['OlinkID', 'UniProt']]\n",
    "    \n",
    "    # Filter rows where OlinkID is in the olink_ids\n",
    "    matching_proteins = olink_to_uniprot[olink_to_uniprot['OlinkID'].isin(olink_ids)]\n",
    "    \n",
    "    # Return the number of unique UniProt IDs\n",
    "    return matching_proteins['UniProt'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: Unique UniProt IDs: 71, Total Olink IDs: 71\n",
      "Sex: Unique UniProt IDs: 0, Total Olink IDs: 0\n",
      "Bmi: Unique UniProt IDs: 60, Total Olink IDs: 60\n"
     ]
    }
   ],
   "source": [
    "# return the number of unique uniprot IDs and total olink IDs in the significant results common\n",
    "for key in significant_results_common.keys():\n",
    "    unique_uniprot_count = count_unique_uniprot_ids_olink(significant_results_common[key]['Protein_ID'].tolist())\n",
    "    total_olink_ids = len(significant_results_common[key]['Protein_ID'].tolist())\n",
    "    print(f\"{key}: Unique UniProt IDs: {unique_uniprot_count}, Total Olink IDs: {total_olink_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5401\n"
     ]
    }
   ],
   "source": [
    "df_pheno_commonsample, df_proteome_commonsample = common(df_unique, use_common_samples=True, use_common_proteins=False)\n",
    "Protein_ID_commonsample = df_proteome_commonsample.columns\n",
    "\n",
    "def olinkid_to_uniprot(olinklist):\n",
    "    df = pd.read_csv(\"../data/Olink_Assay_Annotation_All.csv\")\n",
    "    df = df.loc[:, ['OlinkID', 'UniProt']]\n",
    "    #create a dictionary\n",
    "    olink_to_uniprot = dict(zip(df['OlinkID'], df['UniProt']))\n",
    "    return list(set(list(filter(None, map(lambda olink: olink_to_uniprot.get(olink), olinklist)))))\n",
    "\n",
    "Protein_ID_commonsample_uniprot = olinkid_to_uniprot(Protein_ID_commonsample)\n",
    "\n",
    "#length of the proteins\n",
    "print(len(Protein_ID_commonsample_uniprot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proteins: 5401\n",
      "Number of olinkids: 5405\n",
      "Number of samples: 46\n",
      "Number of proteins: 5405\n",
      "Uncorrected p-value threshold: 0.05\n",
      "Bonferroni correction threshold: 9.250693802035154e-06\n",
      "FDR-corrected p-value threshold for Age: 0.045973955609729375\n",
      "Number of significant results for Age (uncorrected): 578\n",
      "Number of significant results for Age (FDR corrected): 97\n",
      "Number of significant results for Age (Bonferroni corrected): 26\n",
      "Saved all Age associations to ./output/all/olink_age_associations_all_protein_common_sample_fdr_corrected.csv\n",
      "Saved significant Age associations to ./output/significant/olink_age_significant_associations_all_protein_common_sample_fdr_corrected.csv\n",
      "Uncorrected p-value threshold: 0.05\n",
      "Bonferroni correction threshold: 9.250693802035154e-06\n",
      "FDR-corrected p-value threshold for Sex: nan\n",
      "Number of significant results for Sex (uncorrected): 452\n",
      "Number of significant results for Sex (FDR corrected): 0\n",
      "Number of significant results for Sex (Bonferroni corrected): 0\n",
      "Saved all Sex associations to ./output/all/olink_sex_associations_all_protein_common_sample_fdr_corrected.csv\n",
      "Saved significant Sex associations to ./output/significant/olink_sex_significant_associations_all_protein_common_sample_fdr_corrected.csv\n",
      "Uncorrected p-value threshold: 0.05\n",
      "Bonferroni correction threshold: 9.250693802035154e-06\n",
      "FDR-corrected p-value threshold for Bmi: 0.04917692388633838\n",
      "Number of significant results for Bmi (uncorrected): 730\n",
      "Number of significant results for Bmi (FDR corrected): 98\n",
      "Number of significant results for Bmi (Bonferroni corrected): 21\n",
      "Saved all Bmi associations to ./output/all/olink_bmi_associations_all_protein_common_sample_fdr_corrected.csv\n",
      "Saved significant Bmi associations to ./output/significant/olink_bmi_significant_associations_all_protein_common_sample_fdr_corrected.csv\n",
      "Number of total aptamers:  5405 Number of total proteins:  5401\n",
      "Number of lod aptamers:  3226 Number of lod proteins:  3225\n",
      "Number of significant aptamers: 97 Number of significant proteins:  97\n",
      "Protein Breakdown\n",
      "Age: Set 1: 63/1430, Set 2: 25/1411, Set 3: 9/2560\n",
      "Age: Below LoD: 8/3225, Above Lod: 89/2176\n",
      "Aptamer Breakdown\n",
      "Age: Set 1: 63/1430, Set 2: 25/1411, Set 3: 9/2564\n",
      "Age: Below LoD: 8/3226, Above Lod: 89/2179\n",
      "Number of total aptamers:  5405 Number of total proteins:  5401\n",
      "Number of lod aptamers:  3226 Number of lod proteins:  3225\n",
      "Number of significant aptamers: 0 Number of significant proteins:  0\n",
      "Protein Breakdown\n",
      "Sex: Set 1: 0/1430, Set 2: 0/1411, Set 3: 0/2560\n",
      "Sex: Below LoD: 0/3225, Above Lod: 0/2176\n",
      "Aptamer Breakdown\n",
      "Sex: Set 1: 0/1430, Set 2: 0/1411, Set 3: 0/2564\n",
      "Sex: Below LoD: 0/3226, Above Lod: 0/2179\n",
      "Number of total aptamers:  5405 Number of total proteins:  5401\n",
      "Number of lod aptamers:  3226 Number of lod proteins:  3225\n",
      "Number of significant aptamers: 98 Number of significant proteins:  98\n",
      "Protein Breakdown\n",
      "Bmi: Set 1: 56/1430, Set 2: 28/1411, Set 3: 14/2560\n",
      "Bmi: Below LoD: 15/3225, Above Lod: 83/2176\n",
      "Aptamer Breakdown\n",
      "Bmi: Set 1: 56/1430, Set 2: 28/1411, Set 3: 14/2564\n",
      "Bmi: Below LoD: 15/3226, Above Lod: 83/2179\n"
     ]
    }
   ],
   "source": [
    "df_pheno_commonsample, df_proteome_commonsample = common(df_unique, use_common_samples=True, use_common_proteins=False)\n",
    "Protein_ID_commonsample = df_proteome_commonsample.columns\n",
    "Protein_ID_commonsample_uniprot = olinkid_to_uniprot(Protein_ID_commonsample)\n",
    "#lenth of proteins\n",
    "print(f\"Number of proteins: {len(Protein_ID_commonsample_uniprot)}\")\n",
    "print(f\"Number of olinkids: {len(Protein_ID_commonsample)}\")\n",
    "\n",
    "\n",
    "significant_results_commonsample, top_10_commonsample, lookup_result_commonsample, results_commonsample = perform_regression_fdr(df_pheno_commonsample, df_proteome_commonsample, Protein_ID_commonsample, \"olink\", df_proteome_median, type=\"all_protein_common_sample\")\n",
    "for key in significant_results_commonsample.keys():\n",
    "    set1_count_total, set2_count_total, set3_count_total, lod_count, apt_set1_count_total, apt_set2_count_total, apt_set3_count_total, apt_lod_count = return_set_breakdown(Protein_ID_commonsample_uniprot, Protein_ID_commonsample)\n",
    "    significant_aptamers = significant_results_commonsample[key]['Protein_ID'].to_list()\n",
    "    associated_proteins = olinkid_to_uniprot(significant_aptamers)\n",
    "    print(\"Number of total aptamers: \", len(Protein_ID_commonsample), \"Number of total proteins: \", len(Protein_ID_commonsample_uniprot))\n",
    "    print(\"Number of lod aptamers: \", apt_lod_count, \"Number of lod proteins: \", lod_count)\n",
    "    print(f\"Number of significant aptamers: {len(significant_aptamers)}\", \"Number of significant proteins: \", len(associated_proteins))\n",
    "    set1_count_associated, set2_count_associated, set3_count_associated, lod_count_associated, apt_set1_count_associated, apt_set2_count_associated, apt_set3_count_associated, apt_lod_count_associated  = return_set_breakdown(associated_proteins, significant_aptamers)\n",
    "    print(\"Protein Breakdown\")\n",
    "    print (f\"{key}: Set 1: {set1_count_associated}/{set1_count_total}, Set 2: {set2_count_associated}/{set2_count_total}, Set 3: {set3_count_associated}/{set3_count_total}\")\n",
    "    print (f\"{key}: Below LoD: {lod_count_associated}/{lod_count}, Above Lod: {len(associated_proteins) - (lod_count_associated)}/{len(Protein_ID_commonsample_uniprot) - lod_count}\")\n",
    "    print(\"Aptamer Breakdown\")\n",
    "    print (f\"{key}: Set 1: {apt_set1_count_associated}/{apt_set1_count_total}, Set 2: {apt_set2_count_associated}/{apt_set2_count_total}, Set 3: {apt_set3_count_associated}/{apt_set3_count_total}\")\n",
    "    print (f\"{key}: Below LoD: {apt_lod_count_associated}/{apt_lod_count}, Above Lod: {len(significant_aptamers) - (apt_lod_count_associated)}/{len(Protein_ID_commonsample) - apt_lod_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: Unique UniProt IDs: 97, Total Olink IDs: 97\n",
      "Sex: Unique UniProt IDs: 0, Total Olink IDs: 0\n",
      "Bmi: Unique UniProt IDs: 98, Total Olink IDs: 98\n"
     ]
    }
   ],
   "source": [
    "# return the number of unique uniprot IDs and total olink IDs in the significant results common\n",
    "for key in significant_results_commonsample.keys():\n",
    "    unique_uniprot_count = count_unique_uniprot_ids_olink(significant_results_commonsample[key]['Protein_ID'].tolist())\n",
    "    total_olink_ids = len(significant_results_commonsample[key]['Protein_ID'].tolist())\n",
    "    print(f\"{key}: Unique UniProt IDs: {unique_uniprot_count}, Total Olink IDs: {total_olink_ids}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
